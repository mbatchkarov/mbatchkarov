<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Miroslav Batchkarov</title>
    <description>Miroslav Batchkarov&#39;s webspace</description>
    <link>http://mbatchkarov.github.io/</link>
    <atom:link href="http://mbatchkarov.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 14 Jul 2014 17:18:57 +0100</pubDate>
    <lastBuildDate>Mon, 14 Jul 2014 17:18:57 +0100</lastBuildDate>
    <generator>Jekyll v2.1.1</generator>
    
      <item>
        <title>Profiling Python</title>
        <description>&lt;p&gt;This article explains the basics of profiling Python code. The hardest part is&lt;br /&gt;
installing all the great tools that make it trivial to find the bottleneck in&lt;br /&gt;
your code.&lt;/p&gt;

&lt;h2 id=&quot;getting-the-required-tools&quot;&gt;Getting the required tools&lt;/h2&gt;
&lt;p&gt;This can be a pain in the neck on a Mac. The rule of thumb I adhere to is &lt;strong&gt;Use
&lt;code&gt;conda&lt;/code&gt;, &lt;code&gt;pip&lt;/code&gt; and &lt;code&gt;homebrew&lt;/code&gt; where possible&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;python-and-core-packages-numpy-scipy-etc&quot;&gt;Python and core packages (&lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;scipy&lt;/code&gt;, etc)&lt;/h3&gt;
&lt;p&gt;Installing Python modules can sometimes be challenging as these link to compiled
&lt;code&gt;C&lt;/code&gt;/&lt;code&gt;Fortran&lt;/code&gt; code behind the scenes. I recommend using &lt;code&gt;conda&lt;/code&gt;, which can&lt;br /&gt;
install pre-compiled modules for your operating system. Download from&lt;br /&gt;
http://conda.pydata.org/miniconda.html. &lt;code&gt;conda&lt;/code&gt; can be installed to your home&lt;br /&gt;
directory, which comes in handy on the cluster.&lt;/p&gt;

&lt;p&gt;After that, you can easily set up a virtual environment and install many of the core packages:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda create -n py3k anaconda python=3
conda install numpy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first step above should prepend the newly set up Python interpreter to your&lt;br /&gt;
path. If it doesn’t, prepend the path to the new interpreter by editing
&lt;code&gt;~/.bashrc&lt;/code&gt; and &lt;code&gt;~/.bash_profile&lt;/code&gt;. Pip should also be installed— if it is not,&lt;br /&gt;
type  the following into a terminal
&lt;code&gt;
conda install pip
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Once &lt;code&gt;conda&lt;/code&gt; and &lt;code&gt;pip&lt;/code&gt; are up and running, you should always attempt to install&lt;br /&gt;
new Python packages through them instead of from source. This will save a lot of&lt;br /&gt;
headache in the long run as you won’t have to compile &lt;code&gt;C&lt;/code&gt;/&lt;code&gt;Fortran&lt;/code&gt; code.&lt;/p&gt;

&lt;h4 id=&quot;note&quot;&gt;Note&lt;/h4&gt;
&lt;p&gt;Some Python packages serve as a wrapper around other software, such as &lt;code&gt;MySQLdb&lt;/code&gt;&lt;br /&gt;
around &lt;code&gt;mysql&lt;/code&gt; and &lt;code&gt;bsddb&lt;/code&gt; around &lt;code&gt;BerkeleyDB&lt;/code&gt;. The underlying software is best&lt;br /&gt;
installed via &lt;code&gt;homebrew&lt;/code&gt;. For instance, here is how to set up &lt;code&gt;BerkeleyDB&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# install C/Fortran compilers, these will come in handy all the time
brew install gcc
# install berkeley to  /usr/local/Cellar/berkeley-db/&amp;lt;VERSION&amp;gt;
brew install berkeley-db
# install python wrapper, passing in the path to the berkeley-db installation
BERKELEYDB_DIR=/usr/local/Cellar/berkeley-db/5.3.15/ pip install bsddb3
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;profiling-result-visualisation-runsnakerun-snakeviz&quot;&gt;Profiling result visualisation (&lt;code&gt;Runsnakerun&lt;/code&gt;/ &lt;code&gt;Snakeviz&lt;/code&gt;)&lt;/h3&gt;

&lt;p&gt;These tool are useful for finding which function calls take the most time. You&lt;br /&gt;
cannot look inside of functions using these. The next section will explain how&lt;br /&gt;
to profile a single function to find which lines take the most time.&lt;/p&gt;

&lt;p&gt;I know of two great packages the can visualise the output of the Python&lt;br /&gt;
profiler. &lt;code&gt;snakeviz&lt;/code&gt; has some fancy features and written in pure Python. It is&lt;br /&gt;
easier to set up and use, but somewhat slow. If you have profiled a large chunk&lt;br /&gt;
of an application, &lt;code&gt;snakeviz&lt;/code&gt; will give up. In practice, I found it’s only&lt;br /&gt;
useful for small programs. &lt;code&gt;runsnakerun&lt;/code&gt; is written in &lt;code&gt;C&lt;/code&gt;, so it can display&lt;br /&gt;
just about anything, but is somewhat trickier to install.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install snakeviz
pip install runsnakerun
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For &lt;code&gt;runsnakerun&lt;/code&gt;, you may also have to install &lt;code&gt;SquareMap&lt;/code&gt; via &lt;code&gt;brew&lt;/code&gt;/&lt;code&gt;conda&lt;/code&gt;/&lt;code&gt;pip&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To visualise the results of a profiling run with &lt;code&gt;snakeviz&lt;/code&gt; type
&lt;code&gt;
snakeviz out.prof
&lt;/code&gt;&lt;br /&gt;
where &lt;code&gt;out.prof&lt;/code&gt; is the file output by the profiler (see below). If you get
“Sorry, we were not able to load this profile! You can try profiling a smaller&lt;br /&gt;
portion of your code.”, then you will have to use &lt;code&gt;runsnakerun&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ipython qtconsole
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the window that opens, type
&lt;code&gt;
from runsnakerun import runsnake
runsnake.main()
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;then use the GUI to open &lt;code&gt;out.prof&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The reason we are using &lt;code&gt;ipython&lt;/code&gt; instead of launching &lt;code&gt;runsnakerun&lt;/code&gt; from the&lt;br /&gt;
terminal is that OSX restricts some applications’ access to the screen. The&lt;br /&gt;
version of &lt;code&gt;runsnakerun&lt;/code&gt; installed through &lt;code&gt;pip&lt;/code&gt; is not an Apple “framework” and&lt;br /&gt;
therefore cannot access the screen. There are multiple guides explaining how to&lt;br /&gt;
get around this on the Internet, but none of them has worked for me.&lt;/p&gt;

&lt;h3 id=&quot;ipython-extensions&quot;&gt;IPython extensions&lt;/h3&gt;

&lt;p&gt;There are many great tutorials on how to set up and use the required IPython&lt;br /&gt;
  extensions, such as http://pynash.org/2013/03/06/timing-and-profiling.html .&lt;/p&gt;

&lt;p&gt;These extensions are best used to profile single functions (see below). &lt;code&gt;lprun&lt;/code&gt;&lt;br /&gt;
and &lt;code&gt;mprun&lt;/code&gt; are of particular interest. Also note &lt;code&gt;prun&lt;/code&gt; prints as a table the&lt;br /&gt;
same information that &lt;code&gt;snakeviz&lt;/code&gt;/&lt;code&gt;runsnakerun&lt;/code&gt; visualises. Personally I find&lt;br /&gt;
the visualisation much more useful.&lt;/p&gt;

&lt;h2 id=&quot;profiling-the-entire-application&quot;&gt;Profiling the entire application&lt;/h2&gt;

&lt;p&gt;To profile an entire application, run
&lt;code&gt;
python -m cProfile -o out.prof mycode.py
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This creates a file called &lt;code&gt;out.prof&lt;/code&gt;, which can be visualised using &lt;code&gt;snakeviz&lt;/code&gt;&lt;br /&gt;
or &lt;code&gt;runsnakerun&lt;/code&gt;. The visualisation might like this:&lt;/p&gt;

&lt;!-- ![Image](https://dl.dropboxusercontent.com/u/20043416/runsnake.png) --&gt;
&lt;p&gt;&lt;img src=&quot;http://mbatchkarov.github.io/assets/images/runsnake.png&quot; alt=&quot;Image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The top left corner of that image can be read as&lt;br /&gt;
 - function &lt;code&gt;_count_vocab&lt;/code&gt; took a total of 1.6s&lt;br /&gt;
 - 0.6s of which were spent in &lt;code&gt;__contains__&lt;/code&gt; (not visible in the image, you&lt;br /&gt;
   need to hover over the box in &lt;code&gt;runsnakerun&lt;/code&gt;)&lt;br /&gt;
 - 0.2s of which were spent in &lt;code&gt;__my_feature_extractor__&lt;/code&gt;, etc&lt;/p&gt;

&lt;p&gt;This technique can be used to find out which functions take a long time.&lt;/p&gt;

&lt;h2 id=&quot;profiling-functions&quot;&gt;Profiling functions&lt;/h2&gt;

&lt;p&gt;Having set up the required IPython extensions and identified bottleneck functions,&lt;br /&gt;
we can profile and incrementally optimise these. Let’s illustrate this with a real&lt;br /&gt;
example I was recently working on.&lt;/p&gt;

&lt;p&gt;I have a function called &lt;code&gt;calculate_log_odds&lt;/code&gt;, which does something rather&lt;br /&gt;
simple but seems to take a lot of time. To profile it line by line, I ran the&lt;br /&gt;
following command in IPython&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;# get some data to run the function with
import pickle
b = pickle.load(open(&#39;../statistics/stats-exp0-0-cv0-ev.MultinomialNB.pkl&#39;))
X = b.tr_matrix
y = b.y_tr
# do the actual profiling
%lprun -f calculate_log_odds calculate_log_odds(X, y)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;Total time: 2.36018 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
     3                                           def calculate_log_odds(X, y):
     4                                               # todo this is quite slow
     5         1           14     14.0      0.0      log_odds = np.empty(X.shape[1])
     6         1           45     45.0      0.0      class0_indices = (y == sorted(set(y))[0])
     7      2466         1632      0.7      0.1      for idx in range(X.shape[1]):
     8      2465       864021    350.5     36.6          all_counts = X[:, idx].A.ravel()  # document counts of this feature
     9      2465      1378602    559.3     58.4          total_counts = sum(all_counts &amp;gt; 0)  # how many docs the feature occurs in
    10      2465        79524     32.3      3.4          count_in_class0 = sum(all_counts[class0_indices])  # how many of them are class 0
    11      2465         3871      1.6      0.2          p = float(count_in_class0) / total_counts;
    12      2465        29874     12.1      1.3          log_odds_this_feature = np.log(p) - np.log(1 - p)
    13      2465         2595      1.1      0.1          log_odds[idx] = log_odds_this_feature
    14         1            0      0.0      0.0      return log_odds

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Most of the time is spent on line 9, where I am using the Python &lt;code&gt;sum&lt;/code&gt; function&lt;br /&gt;
to add up a &lt;code&gt;numpy&lt;/code&gt; array. This can be made much faster by using the appropriate&lt;br /&gt;
numpy function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;Function: calculate_log_odds2 at line 16
Total time: 1.54092 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    16                                           def calculate_log_odds2(X, y):
    17         1           16     16.0      0.0      log_odds = np.empty(X.shape[1])
    18         1           55     55.0      0.0      class0_indices = (y == sorted(set(y))[0])
    19         1          526    526.0      0.0      X = X.tocsc()
    20      2466         1746      0.7      0.1      for idx in range(X.shape[1]):
    21      2465      1417910    575.2     92.0          all_counts = X[:, idx].A.ravel()  # document counts of this feature
    22      2465        49792     20.2      3.2          total_counts = np.sum(all_counts &amp;gt; 0)  # how many docs the feature occurs in
    23      2465        32936     13.4      2.1          count_in_class0 = np.sum(all_counts[class0_indices])  # how many of them are class 0
    24      2465         4377      1.8      0.3          p = float(count_in_class0) / total_counts;
    25      2465        30788     12.5      2.0          log_odds_this_feature = np.log(p) - np.log(1 - p)
    26      2465         2769      1.1      0.2          log_odds[idx] = log_odds_this_feature
    27         1            1      1.0      0.0      return log_odds

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note the running time has gone down from 2.3s to 1.5s. Now the bottleneck of the&lt;br /&gt;
function seems to be at line 21, where I slice a sparse matrix and unnecessarily&lt;br /&gt;
convert to it a dense one. After a few more iterations of 1) find bottleneck line, and 2) correct line, I&lt;br /&gt;
arrived at the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;Total time: 0.058181 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    56                                           def calculate_log_odds5(X, y):
    57         1           13     13.0      0.0      log_odds = np.empty(X.shape[1])
    58         1           47     47.0      0.1      class0_indices = y == sorted(set(y))[0]
    59         1          619    619.0      1.1      X = X.A
    60      2466         1792      0.7      3.1      for idx in range(X.shape[1]):
    61      2465         8277      3.4     14.2          all_counts = X[:, idx]  # document counts of this feature
    62      2465         7354      3.0     12.6          total_counts = np.count_nonzero(all_counts)  # how many docs the feature occurs in
    63      2465         8044      3.3     13.8          count_in_class0 = np.count_nonzero(all_counts[class0_indices])  # how many of them are class 0
    64      2465         3521      1.4      6.1          p = float(count_in_class0) / total_counts
    65      2465        25890     10.5     44.5          log_odds_this_feature = np.log(p) - np.log(1 - p)
    66      2465         2623      1.1      4.5          log_odds[idx] = log_odds_this_feature
    67         1            1      1.0      0.0      return log_odds
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The running time is now 0.05 seconds, or a speedup of ~50x. The bottleneck&lt;br /&gt;
operation is now entirely done on &lt;code&gt;numpy&lt;/code&gt; arrays, so there are no more&lt;br /&gt;
low-hanging fruit.&lt;/p&gt;

&lt;h4 id=&quot;notes&quot;&gt;Notes&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Having unit tests for the functions that you are optimising is essential&lt;br /&gt;
to making sure nothing gets broken.&lt;/li&gt;
  &lt;li&gt;Functions to be profiled line by line cannot be typed into the interactive shell&lt;br /&gt;
and  must be imported from a file on disk&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 14 Jul 2014 15:52:58 +0100</pubDate>
        <link>http://mbatchkarov.github.io/2014/07/14/profiling-python/</link>
        <guid isPermaLink="true">http://mbatchkarov.github.io/2014/07/14/profiling-python/</guid>
        
        <category>python</category>
        
        <category>profiling</category>
        
        <category>performance</category>
        
        
      </item>
    
  </channel>
</rss>
